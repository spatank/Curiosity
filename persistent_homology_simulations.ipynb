{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "persistent_homology_simulations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNQjmAEtLmvIC6b8MGkQE1r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spatank/Curiosity/blob/master/v8/persistent_homology_simulations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y7gnEocgMi0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea98f57c-e89d-4e66-d7cd-f9b7d3be90b0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/Curiosity_v8/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvB4MASbhE5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54899a9e-b1b2-47db-b039-dc1c227e1003"
      },
      "source": [
        "!ls # run !ls to verify location"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "build_Wiki_networks.ipynb\tpersistent_homology_simulations.ipynb  Wiki\n",
            "KNOT\t\t\t\tpersistent_homology_Wiki.ipynb\n",
            "persistent_homology_KNOT.ipynb\tSimulations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6URroOyhdr7"
      },
      "source": [
        "import glob\n",
        "import scipy\n",
        "import scipy.io as sio\n",
        "from scipy.io import savemat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHNE6dZ9kzUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f6a251e-9c41-4aeb-da0d-bf585cd57f84"
      },
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install Cython"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (0.29.23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbhBikHYk6TO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4edb1639-f7fd-413a-ec69-e81adb3d5601"
      },
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install Ripser\n",
        "\n",
        "from ripser import ripser"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Ripser\n",
            "  Downloading ripser-0.6.0.tar.gz (71 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▋                           | 10 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 20 kB 27.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 30 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 40 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 51 kB 33.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 61 kB 34.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71 kB 8.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from Ripser) (0.29.23)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from Ripser) (0.22.2.post1)\n",
            "Collecting persim\n",
            "  Downloading persim-0.3.1-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from Ripser) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from Ripser) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from persim->Ripser) (3.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from persim->Ripser) (1.0.1)\n",
            "Collecting hopcroftkarp\n",
            "  Downloading hopcroftkarp-1.2.5.tar.gz (16 kB)\n",
            "Collecting deprecated\n",
            "  Downloading Deprecated-1.2.12-py2.py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated->persim->Ripser) (1.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->persim->Ripser) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->persim->Ripser) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->persim->Ripser) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->persim->Ripser) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->persim->Ripser) (1.15.0)\n",
            "Building wheels for collected packages: Ripser, hopcroftkarp\n",
            "  Building wheel for Ripser (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Ripser: filename=ripser-0.6.0-cp37-cp37m-linux_x86_64.whl size=454976 sha256=1970f9a1781844e2d7e287b5d10368662b04f0bc019ded07aafb89ff5277ec33\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/b2/61/e9e1faaee99a8c232366e211456483ed0215c171f5b3db2f6f\n",
            "  Building wheel for hopcroftkarp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hopcroftkarp: filename=hopcroftkarp-1.2.5-py2.py3-none-any.whl size=18119 sha256=fa101a955f78cb3b8eccfdb9cc792f60acf05958934fceaa0221b90e8863da6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/9f/a8/67f1b86e47cd17338d3d07939f4660378e65b758c4594f96e3\n",
            "Successfully built Ripser hopcroftkarp\n",
            "Installing collected packages: hopcroftkarp, deprecated, persim, Ripser\n",
            "Successfully installed Ripser-0.6.0 deprecated-1.2.12 hopcroftkarp-1.2.5 persim-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW2lwi2zk9UP"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_barcode(filt_mat, maxdim = 2):\n",
        "    \"\"\"\n",
        "    Calculates the persistent homology for a given filtration matrix\n",
        "    ``filt_mat``, default dimensions 0 through 2. Wraps ripser.\n",
        "    \"\"\"\n",
        "    b = ripser(filt_mat, distance_matrix = True, maxdim = maxdim)['dgms']\n",
        "    return list(zip(range(maxdim + 1), b))\n",
        "\n",
        "def plot_barcode(bars, length, dims = [0, 1, 2], end = True):\n",
        "    \"\"\"\n",
        "    Takes in bars, as generated by, e.g., ripser, and plots the barcode.\n",
        "    \"\"\"\n",
        "    bars = dict(bars)\n",
        "    count = 1\n",
        "    has_inf = False\n",
        "    colors = ['xkcd:emerald green', 'xkcd:tealish', 'xkcd:peacock blue']\n",
        "    # iterate through dimension\n",
        "    for d in dims:\n",
        "        bn = bars[d]\n",
        "        bn = sorted(bn, key = lambda x: x[0])\n",
        "        for b, i in zip(bn, range(len(bn))):\n",
        "            # extend in the case of infinite cycles\n",
        "            if b[1] == np.inf:\n",
        "                has_inf = True\n",
        "                b = (b[0], 1.3*length)\n",
        "            # plot first one with label\n",
        "            if i == 0:\n",
        "                plt.plot(b, [count, count], color = colors[d],\n",
        "                         label='{}-cycles'.format(d))\n",
        "            else:\n",
        "                plt.plot(b, [count, count], color = colors[d])\n",
        "            count += 1\n",
        "        count += 1\n",
        "    # add end of filtration line\n",
        "    plt.axvline(x = length, color = 'xkcd:grey', alpha = 0.5, linestyle = ':')\n",
        "    if end:\n",
        "        plt.annotate('Filtration End', (length + 10, 0.5 * count), rotation = 270,\n",
        "                     color = 'xkcd:grey', alpha = 0.5)\n",
        "    lims = plt.xlim()\n",
        "    plt.xlim([-0.05 * length, length * 1.05])\n",
        "    plt.xlabel('Nodes')\n",
        "    plt.ylabel('Cycle Number')\n",
        "\n",
        "def betti_curves(bars, length):\n",
        "    \"\"\"\n",
        "    Takes in bars and returns the betti curves\n",
        "    \"\"\"\n",
        "    bettis = np.zeros((len(bars), length))\n",
        "    for i in range(bettis.shape[0]):\n",
        "        bn = bars[i][1]\n",
        "        for bar in bn:\n",
        "            birth = int(bar[0])\n",
        "            death = length+1 if np.isinf(bar[1]) else int(bar[1]+1)\n",
        "            bettis[i][birth:death] += 1\n",
        "    return bettis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-Y-VSh2r9xO"
      },
      "source": [
        "mat_file = '/content/drive/My Drive/Curiosity_v8/Simulations/simulated_nets.mat'\n",
        "mat_contents = sio.loadmat(mat_file)\n",
        "\n",
        "CP_nets = mat_contents['const_prob_nets']\n",
        "CP_nets_weighted = mat_contents['const_prob_nets_weighted']\n",
        "PP_nets = mat_contents['prop_prob_nets']\n",
        "PP_nets_weighted = mat_contents['prop_prob_nets_weighted']\n",
        "PA_nets = mat_contents['PA_nets']\n",
        "PA_nets_weighted = mat_contents['PA_nets_weighted']\n",
        "\n",
        "num_nodes = CP_nets_weighted.shape[0]\n",
        "num_iters = CP_nets_weighted.shape[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBFF7eQ62Ypk",
        "outputId": "28c878ed-8b45-4ddb-b2b2-c94c3c07fe37"
      },
      "source": [
        "for iter in range(num_iters):\n",
        "\n",
        "  print('Beginning iter. %d' % iter)\n",
        "  \n",
        "  # Run persistent homology for `constant probability' networks\n",
        "  bettis_0_CP = []\n",
        "  bettis_1_CP = []\n",
        "  bettis_2_CP = []\n",
        "  for i in range(num_iters):\n",
        "    bars_CP = get_barcode(CP_nets_weighted[:, :, i])\n",
        "    bettis_CP = betti_curves(bars_CP, num_nodes)\n",
        "    bettis_0_CP.append(bettis_CP[0])\n",
        "    bettis_1_CP.append(bettis_CP[1])\n",
        "    bettis_2_CP.append(bettis_CP[2])\n",
        "\n",
        "  # Run persistent homology for `proportional probability' networks\n",
        "  bettis_0_PP = []\n",
        "  bettis_1_PP = []\n",
        "  bettis_2_PP = []\n",
        "  for i in range(num_iters):\n",
        "    bars_PP = get_barcode(PP_nets_weighted[:, :, i])\n",
        "    bettis_PP = betti_curves(bars_PP, num_nodes)\n",
        "    bettis_0_PP.append(bettis_PP[0])\n",
        "    bettis_1_PP.append(bettis_PP[1])\n",
        "    bettis_2_PP.append(bettis_PP[2])\n",
        "\n",
        "  # Run persistent homology for `preferential attachment' networks\n",
        "  bettis_0_PA = []\n",
        "  bettis_1_PA = []\n",
        "  bettis_2_PA = []\n",
        "  for i in range(num_iters):\n",
        "    bars_PA = get_barcode(PA_nets_weighted[:, :, i])\n",
        "    bettis_PA = betti_curves(bars_PA, num_nodes)\n",
        "    bettis_0_PA.append(bettis_PA[0])\n",
        "    bettis_1_PA.append(bettis_PA[1])\n",
        "    bettis_2_PA.append(bettis_PA[2])\n",
        "\n",
        "  print('Processed iter. %d' % iter)\n",
        "\n",
        "base_path = '/content/drive/My Drive/Curiosity_v8/Simulations/'\n",
        "\n",
        "# Store all PH results (one example barcode for each network model)\n",
        "save_dict = {'num_nodes': num_nodes,\n",
        "             'bars_CP': bars_CP,\n",
        "             'bettis_0_CP': bettis_0_CP, \n",
        "             'bettis_1_CP': bettis_1_CP,\n",
        "             'bettis_2_CP': bettis_2_CP,\n",
        "             'bars_PP': bars_PP,\n",
        "             'bettis_0_PP': bettis_0_PP,\n",
        "             'bettis_1_PP': bettis_1_PP,\n",
        "             'bettis_2_PP': bettis_2_PP,\n",
        "             'bars_PA': bars_PA,\n",
        "             'bettis_0_PA': bettis_0_PA,\n",
        "             'bettis_1_PA': bettis_1_PA,\n",
        "             'bettis_2_PA': bettis_2_PA}\n",
        "             \n",
        "np.save(base_path + 'simulated_nets_PH.npy', save_dict, allow_pickle = True) \n",
        "savemat(base_path + 'simulated_nets_PH.mat', save_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning iter. 0\n",
            "Processed iter. 0\n",
            "Beginning iter. 1\n",
            "Processed iter. 1\n",
            "Beginning iter. 2\n",
            "Processed iter. 2\n",
            "Beginning iter. 3\n",
            "Processed iter. 3\n",
            "Beginning iter. 4\n",
            "Processed iter. 4\n",
            "Beginning iter. 5\n",
            "Processed iter. 5\n",
            "Beginning iter. 6\n",
            "Processed iter. 6\n",
            "Beginning iter. 7\n",
            "Processed iter. 7\n",
            "Beginning iter. 8\n",
            "Processed iter. 8\n",
            "Beginning iter. 9\n",
            "Processed iter. 9\n",
            "Beginning iter. 10\n",
            "Processed iter. 10\n",
            "Beginning iter. 11\n",
            "Processed iter. 11\n",
            "Beginning iter. 12\n",
            "Processed iter. 12\n",
            "Beginning iter. 13\n",
            "Processed iter. 13\n",
            "Beginning iter. 14\n",
            "Processed iter. 14\n",
            "Beginning iter. 15\n",
            "Processed iter. 15\n",
            "Beginning iter. 16\n",
            "Processed iter. 16\n",
            "Beginning iter. 17\n",
            "Processed iter. 17\n",
            "Beginning iter. 18\n",
            "Processed iter. 18\n",
            "Beginning iter. 19\n",
            "Processed iter. 19\n",
            "Beginning iter. 20\n",
            "Processed iter. 20\n",
            "Beginning iter. 21\n",
            "Processed iter. 21\n",
            "Beginning iter. 22\n",
            "Processed iter. 22\n",
            "Beginning iter. 23\n",
            "Processed iter. 23\n",
            "Beginning iter. 24\n",
            "Processed iter. 24\n",
            "Beginning iter. 25\n",
            "Processed iter. 25\n",
            "Beginning iter. 26\n",
            "Processed iter. 26\n",
            "Beginning iter. 27\n",
            "Processed iter. 27\n",
            "Beginning iter. 28\n",
            "Processed iter. 28\n",
            "Beginning iter. 29\n",
            "Processed iter. 29\n",
            "Beginning iter. 30\n",
            "Processed iter. 30\n",
            "Beginning iter. 31\n",
            "Processed iter. 31\n",
            "Beginning iter. 32\n",
            "Processed iter. 32\n",
            "Beginning iter. 33\n",
            "Processed iter. 33\n",
            "Beginning iter. 34\n",
            "Processed iter. 34\n",
            "Beginning iter. 35\n",
            "Processed iter. 35\n",
            "Beginning iter. 36\n",
            "Processed iter. 36\n",
            "Beginning iter. 37\n",
            "Processed iter. 37\n",
            "Beginning iter. 38\n",
            "Processed iter. 38\n",
            "Beginning iter. 39\n",
            "Processed iter. 39\n",
            "Beginning iter. 40\n",
            "Processed iter. 40\n",
            "Beginning iter. 41\n",
            "Processed iter. 41\n",
            "Beginning iter. 42\n",
            "Processed iter. 42\n",
            "Beginning iter. 43\n",
            "Processed iter. 43\n",
            "Beginning iter. 44\n",
            "Processed iter. 44\n",
            "Beginning iter. 45\n",
            "Processed iter. 45\n",
            "Beginning iter. 46\n",
            "Processed iter. 46\n",
            "Beginning iter. 47\n",
            "Processed iter. 47\n",
            "Beginning iter. 48\n",
            "Processed iter. 48\n",
            "Beginning iter. 49\n",
            "Processed iter. 49\n",
            "Beginning iter. 50\n",
            "Processed iter. 50\n",
            "Beginning iter. 51\n",
            "Processed iter. 51\n",
            "Beginning iter. 52\n",
            "Processed iter. 52\n",
            "Beginning iter. 53\n",
            "Processed iter. 53\n",
            "Beginning iter. 54\n",
            "Processed iter. 54\n",
            "Beginning iter. 55\n",
            "Processed iter. 55\n",
            "Beginning iter. 56\n",
            "Processed iter. 56\n",
            "Beginning iter. 57\n",
            "Processed iter. 57\n",
            "Beginning iter. 58\n",
            "Processed iter. 58\n",
            "Beginning iter. 59\n",
            "Processed iter. 59\n",
            "Beginning iter. 60\n",
            "Processed iter. 60\n",
            "Beginning iter. 61\n",
            "Processed iter. 61\n",
            "Beginning iter. 62\n",
            "Processed iter. 62\n",
            "Beginning iter. 63\n",
            "Processed iter. 63\n",
            "Beginning iter. 64\n",
            "Processed iter. 64\n",
            "Beginning iter. 65\n",
            "Processed iter. 65\n",
            "Beginning iter. 66\n",
            "Processed iter. 66\n",
            "Beginning iter. 67\n",
            "Processed iter. 67\n",
            "Beginning iter. 68\n",
            "Processed iter. 68\n",
            "Beginning iter. 69\n",
            "Processed iter. 69\n",
            "Beginning iter. 70\n",
            "Processed iter. 70\n",
            "Beginning iter. 71\n",
            "Processed iter. 71\n",
            "Beginning iter. 72\n",
            "Processed iter. 72\n",
            "Beginning iter. 73\n",
            "Processed iter. 73\n",
            "Beginning iter. 74\n",
            "Processed iter. 74\n",
            "Beginning iter. 75\n",
            "Processed iter. 75\n",
            "Beginning iter. 76\n",
            "Processed iter. 76\n",
            "Beginning iter. 77\n",
            "Processed iter. 77\n",
            "Beginning iter. 78\n",
            "Processed iter. 78\n",
            "Beginning iter. 79\n",
            "Processed iter. 79\n",
            "Beginning iter. 80\n",
            "Processed iter. 80\n",
            "Beginning iter. 81\n",
            "Processed iter. 81\n",
            "Beginning iter. 82\n",
            "Processed iter. 82\n",
            "Beginning iter. 83\n",
            "Processed iter. 83\n",
            "Beginning iter. 84\n",
            "Processed iter. 84\n",
            "Beginning iter. 85\n",
            "Processed iter. 85\n",
            "Beginning iter. 86\n",
            "Processed iter. 86\n",
            "Beginning iter. 87\n",
            "Processed iter. 87\n",
            "Beginning iter. 88\n",
            "Processed iter. 88\n",
            "Beginning iter. 89\n",
            "Processed iter. 89\n",
            "Beginning iter. 90\n",
            "Processed iter. 90\n",
            "Beginning iter. 91\n",
            "Processed iter. 91\n",
            "Beginning iter. 92\n",
            "Processed iter. 92\n",
            "Beginning iter. 93\n",
            "Processed iter. 93\n",
            "Beginning iter. 94\n",
            "Processed iter. 94\n",
            "Beginning iter. 95\n",
            "Processed iter. 95\n",
            "Beginning iter. 96\n",
            "Processed iter. 96\n",
            "Beginning iter. 97\n",
            "Processed iter. 97\n",
            "Beginning iter. 98\n",
            "Processed iter. 98\n",
            "Beginning iter. 99\n",
            "Processed iter. 99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}