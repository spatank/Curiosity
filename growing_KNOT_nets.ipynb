{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "growing_KNOT_nets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8R1QEdNErikN8pru18RDU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spatank/Curiosity/blob/master/growing_KNOT_nets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FUJYyJqJhIP"
      },
      "source": [
        "Make data available to Colab by mounting your Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt4lKf68BBEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a43abfee-04ea-4774-ed1b-bbdd9ce14926"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/Curiosity_IGT/KNOT')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAcMQZG0C_FC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ed1044-33e4-46b9-afe4-ea5b7cd68219"
      },
      "source": [
        "!ls # run !ls to verify location "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "growing_KNOT_nets.ipynb  KNOT_data_processed  KNOT_data_raw.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ku8aDAUJwjE"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5Qpip15Eb1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed8a45a-da35-4ff2-816a-fc226eca7d7b"
      },
      "source": [
        "import pandas as pd\n",
        "!pip install wikipedia2vec\n",
        "from wikipedia2vec import Wikipedia2Vec\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "from scipy.io import savemat\n",
        "import networkx as nx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wikipedia2vec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/88/751037c70ca86581d444824e66bb799ef9060339a1d5d1fc1804c422d7cc/wikipedia2vec-1.0.4.tar.gz (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (7.1.2)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (0.42.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (1.0.0)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (0.99)\n",
            "Collecting marisa-trie\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/95/d23071d0992dabcb61c948fb118a90683193befc88c23e745b050a29e7db/marisa-trie-0.7.5.tar.gz (270kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 40.2MB/s \n",
            "\u001b[?25hCollecting mwparserfromhell\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/00/03ccc2676e592f73ce455fd0343eb38d3779878332ba01ef4c0281a7d2a9/mwparserfromhell-0.6-cp36-cp36m-manylinux1_x86_64.whl (174kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 18.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (1.19.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (4.41.1)\n",
            "Building wheels for collected packages: wikipedia2vec, marisa-trie\n",
            "  Building wheel for wikipedia2vec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia2vec: filename=wikipedia2vec-1.0.4-cp36-cp36m-linux_x86_64.whl size=4581798 sha256=f3175553b308327ef99158db522a4a91222c55052e14c51d8dbc45c66982824b\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/e7/02/852c8ce366cc10adcf5d43c6471bbf926dd15c277578c13184\n",
            "  Building wheel for marisa-trie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for marisa-trie: filename=marisa_trie-0.7.5-cp36-cp36m-linux_x86_64.whl size=861076 sha256=962d392a021d0055ea56ca3c4b282608247d4a5fc416470c9aa424e064889de2\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/24/79/022624fc914f0e559fe8a1141aaff1f9df810905a13fc75d57\n",
            "Successfully built wikipedia2vec marisa-trie\n",
            "Installing collected packages: marisa-trie, mwparserfromhell, wikipedia2vec\n",
            "Successfully installed marisa-trie-0.7.5 mwparserfromhell-0.6 wikipedia2vec-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9QmgTY9KF_A"
      },
      "source": [
        "# Data Wrangling\n",
        "\n",
        "This section pre-processes the KNOT data to get it into a format suited to network analysis. The data contains the names of Wikipedia pages visited by a participant in two columns: `SourceName` and `TargetName`. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRCVHGiwzEBd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "cf8698df-52ee-47a8-ba98-3ded761d09b9"
      },
      "source": [
        "wiki_df = pd.read_csv('KNOT_data_raw.csv')\n",
        "wiki_df.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>SourceName</th>\n",
              "      <th>TargetName</th>\n",
              "      <th>Day</th>\n",
              "      <th>TimeOrder</th>\n",
              "      <th>Hyperlink</th>\n",
              "      <th>DistanceWeights</th>\n",
              "      <th>AgeYears</th>\n",
              "      <th>SexOrient</th>\n",
              "      <th>Race</th>\n",
              "      <th>GenderFactor</th>\n",
              "      <th>EducDeg</th>\n",
              "      <th>Income</th>\n",
              "      <th>JE_5D</th>\n",
              "      <th>DS_5D</th>\n",
              "      <th>ST_5D</th>\n",
              "      <th>SC_5D</th>\n",
              "      <th>TS_5D</th>\n",
              "      <th>Count</th>\n",
              "      <th>Weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>/wiki/Jeff_Bezos</td>\n",
              "      <td>/wiki/Cloud_infrastructure</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.27945</td>\n",
              "      <td>Heterosexual</td>\n",
              "      <td>AsiaAm</td>\n",
              "      <td>0</td>\n",
              "      <td>BachDegree</td>\n",
              "      <td>20to49k</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.25</td>\n",
              "      <td>1.6</td>\n",
              "      <td>2.8</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101</td>\n",
              "      <td>/wiki/Cloud_infrastructure</td>\n",
              "      <td>/wiki/Cloud_computing_security</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.2</td>\n",
              "      <td>23.27945</td>\n",
              "      <td>Heterosexual</td>\n",
              "      <td>AsiaAm</td>\n",
              "      <td>0</td>\n",
              "      <td>BachDegree</td>\n",
              "      <td>20to49k</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.25</td>\n",
              "      <td>1.6</td>\n",
              "      <td>2.8</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>101</td>\n",
              "      <td>/wiki/Cloud_computing_security</td>\n",
              "      <td>/wiki/Cloud_infrastructure</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>0.2</td>\n",
              "      <td>23.27945</td>\n",
              "      <td>Heterosexual</td>\n",
              "      <td>AsiaAm</td>\n",
              "      <td>0</td>\n",
              "      <td>BachDegree</td>\n",
              "      <td>20to49k</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.25</td>\n",
              "      <td>1.6</td>\n",
              "      <td>2.8</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    ID                      SourceName  ... Count  Weight\n",
              "0  101                /wiki/Jeff_Bezos  ...     1     0.0\n",
              "1  101      /wiki/Cloud_infrastructure  ...     2     0.8\n",
              "2  101  /wiki/Cloud_computing_security  ...     3     0.8\n",
              "\n",
              "[3 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afyM5cEyyyYH"
      },
      "source": [
        "def clean_entity_name(name):\n",
        "  name = name.replace('/wiki/', '')\n",
        "  name = name.replace('_', ' ')\n",
        "  return name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxXehM8xMH32"
      },
      "source": [
        "First, we create unique identifiers (UIDs) for each page so that they can be used as nodes in a network representation. Then we clean the strings associated with each page by stripping redundant information such as `wiki/` and `_`. The UIDs and clean names are appended to the data frame as new columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So4CNo4-xggB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "d24e0b1d-586f-4425-cb00-02c01cf78025"
      },
      "source": [
        "# create UID for each page\n",
        "source_nodes = set(wiki_df['SourceName'].tolist())\n",
        "target_nodes = set(wiki_df['TargetName'].tolist())\n",
        "source_nodes.update(target_nodes)\n",
        "node_set = {entity: name for name, entity in enumerate(source_nodes)}\n",
        "wiki_df['SourceUID'] = wiki_df['SourceName'].apply(lambda x: node_set[x])\n",
        "wiki_df['SrcNameClean'] = wiki_df['SourceName'].apply(lambda x: clean_entity_name(x))\n",
        "wiki_df['TargetUID'] = wiki_df['TargetName'].apply(lambda x: node_set[x])\n",
        "wiki_df['TgtNameClean'] = wiki_df['TargetName'].apply(lambda x: clean_entity_name(x))\n",
        "wiki_df.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>SourceName</th>\n",
              "      <th>TargetName</th>\n",
              "      <th>Day</th>\n",
              "      <th>TimeOrder</th>\n",
              "      <th>Hyperlink</th>\n",
              "      <th>DistanceWeights</th>\n",
              "      <th>AgeYears</th>\n",
              "      <th>SexOrient</th>\n",
              "      <th>Race</th>\n",
              "      <th>GenderFactor</th>\n",
              "      <th>EducDeg</th>\n",
              "      <th>Income</th>\n",
              "      <th>JE_5D</th>\n",
              "      <th>DS_5D</th>\n",
              "      <th>ST_5D</th>\n",
              "      <th>SC_5D</th>\n",
              "      <th>TS_5D</th>\n",
              "      <th>Count</th>\n",
              "      <th>Weight</th>\n",
              "      <th>SourceUID</th>\n",
              "      <th>SrcNameClean</th>\n",
              "      <th>TargetUID</th>\n",
              "      <th>TgtNameClean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>/wiki/Jeff_Bezos</td>\n",
              "      <td>/wiki/Cloud_infrastructure</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.27945</td>\n",
              "      <td>Heterosexual</td>\n",
              "      <td>AsiaAm</td>\n",
              "      <td>0</td>\n",
              "      <td>BachDegree</td>\n",
              "      <td>20to49k</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.25</td>\n",
              "      <td>1.6</td>\n",
              "      <td>2.8</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15859</td>\n",
              "      <td>Jeff Bezos</td>\n",
              "      <td>1065</td>\n",
              "      <td>Cloud infrastructure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101</td>\n",
              "      <td>/wiki/Cloud_infrastructure</td>\n",
              "      <td>/wiki/Cloud_computing_security</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.2</td>\n",
              "      <td>23.27945</td>\n",
              "      <td>Heterosexual</td>\n",
              "      <td>AsiaAm</td>\n",
              "      <td>0</td>\n",
              "      <td>BachDegree</td>\n",
              "      <td>20to49k</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.25</td>\n",
              "      <td>1.6</td>\n",
              "      <td>2.8</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1065</td>\n",
              "      <td>Cloud infrastructure</td>\n",
              "      <td>4050</td>\n",
              "      <td>Cloud computing security</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>101</td>\n",
              "      <td>/wiki/Cloud_computing_security</td>\n",
              "      <td>/wiki/Cloud_infrastructure</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>0.2</td>\n",
              "      <td>23.27945</td>\n",
              "      <td>Heterosexual</td>\n",
              "      <td>AsiaAm</td>\n",
              "      <td>0</td>\n",
              "      <td>BachDegree</td>\n",
              "      <td>20to49k</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.25</td>\n",
              "      <td>1.6</td>\n",
              "      <td>2.8</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.8</td>\n",
              "      <td>4050</td>\n",
              "      <td>Cloud computing security</td>\n",
              "      <td>1065</td>\n",
              "      <td>Cloud infrastructure</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    ID                      SourceName  ... TargetUID              TgtNameClean\n",
              "0  101                /wiki/Jeff_Bezos  ...      1065      Cloud infrastructure\n",
              "1  101      /wiki/Cloud_infrastructure  ...      4050  Cloud computing security\n",
              "2  101  /wiki/Cloud_computing_security  ...      1065      Cloud infrastructure\n",
              "\n",
              "[3 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htTA6-qsXrJO"
      },
      "source": [
        "Extract all curiosity measures from the dataframe for each participant."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sp6pgVVavHu"
      },
      "source": [
        "# joyous exploration\n",
        "# deprivation sensitivity\n",
        "# stress tolerance\n",
        "# social curiosity\n",
        "# thrill seeking\n",
        "five_D = wiki_df.groupby('ID', as_index = False)[['JE_5D', 'DS_5D', 'ST_5D', 'SC_5D', 'TS_5D']].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5c5dky6bYEQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "57dff0c4-5df2-465e-88b3-31301a6f3013"
      },
      "source": [
        "five_D"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>JE_5D</th>\n",
              "      <th>DS_5D</th>\n",
              "      <th>ST_5D</th>\n",
              "      <th>SC_5D</th>\n",
              "      <th>TS_5D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.25</td>\n",
              "      <td>1.6</td>\n",
              "      <td>2.8</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>104</td>\n",
              "      <td>3.2</td>\n",
              "      <td>2.50</td>\n",
              "      <td>2.4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>105</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>5.6</td>\n",
              "      <td>3.50</td>\n",
              "      <td>1.4</td>\n",
              "      <td>5.2</td>\n",
              "      <td>1.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>107</td>\n",
              "      <td>3.4</td>\n",
              "      <td>2.75</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>355</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>356</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.40</td>\n",
              "      <td>1.4</td>\n",
              "      <td>4.2</td>\n",
              "      <td>3.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>359</td>\n",
              "      <td>5.6</td>\n",
              "      <td>5.00</td>\n",
              "      <td>1.8</td>\n",
              "      <td>5.8</td>\n",
              "      <td>4.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>363</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.80</td>\n",
              "      <td>2.6</td>\n",
              "      <td>4.4</td>\n",
              "      <td>2.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>340340</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>3.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>3.20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>149 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID  JE_5D  DS_5D  ST_5D  SC_5D  TS_5D\n",
              "0       101    4.4   4.25    1.6    2.8   2.00\n",
              "1       104    3.2   2.50    2.4    4.0   0.00\n",
              "2       105    3.0   3.00    3.0    2.4   1.00\n",
              "3       106    5.6   3.50    1.4    5.2   1.25\n",
              "4       107    3.4   2.75    2.5    2.4   0.75\n",
              "..      ...    ...    ...    ...    ...    ...\n",
              "144     355    4.6   3.20    3.2    4.8   1.00\n",
              "145     356    4.6   4.40    1.4    4.2   3.00\n",
              "146     359    5.6   5.00    1.8    5.8   4.40\n",
              "147     363    4.6   4.80    2.6    4.4   2.80\n",
              "148  340340    4.0   2.00    3.4    2.6   3.20\n",
              "\n",
              "[149 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uppZavcIwBX5"
      },
      "source": [
        "filename = 'five_D.mat'\n",
        "mdic = {name: col.values for name, col in five_D.items()}\n",
        "savemat(filename, mdic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1ja7sTbMc93"
      },
      "source": [
        "# Wikipedia2Vec\n",
        "\n",
        "Each row in the data frame represents a transition made by a participant from one Wikipedia page to another. The associated edge weight can be obtained as the semantic distance between the contents of the two pages. In order to quantify the semantic distance between Wikipedia entities, we use a pre-trained model that represents each page as an n-dimensional vector. The distance between two pages `SemanticDist` is then computed as the cosine (dis)similarity between their vector representations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKcyjPP_eSXO"
      },
      "source": [
        "model_file = 'enwiki_20180420_300d.pkl'\n",
        "wiki2vec = Wikipedia2Vec.load(model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzt7GJ2y8T38"
      },
      "source": [
        "def check_entity_vector(entity):\n",
        "  try:\n",
        "    vec = wiki2vec.get_entity_vector(entity)\n",
        "    return 0\n",
        "  except KeyError:\n",
        "    return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDgL6zC17xjT"
      },
      "source": [
        "no_vec_entities = []\n",
        "for k, v in node_set.items():\n",
        "  entity = clean_entity_name(k)\n",
        "  no_vec_entities.append(check_entity_vector(entity))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qbdwg6H8f_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05bc80fa-22b2-416f-d13e-f610a4bc0061"
      },
      "source": [
        "len(no_vec_entities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVKxX2Zr8iMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfa01096-75ab-4dbf-d994-1ffbd1631de1"
      },
      "source": [
        "sum(no_vec_entities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2207"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO85sKmQ8tzM"
      },
      "source": [
        "12% of the pages visited by participants in the KNOT data do not have corresponding vector embeddings. We represent these pages by a random vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fchZpOmIRKKh"
      },
      "source": [
        "def semantic_dist(entity_1, entity_2):\n",
        "  # get entity 1 vector\n",
        "  try:\n",
        "    v1 = wiki2vec.get_entity_vector(entity_1)\n",
        "  except KeyError:\n",
        "    v1 = np.random.random(300)\n",
        "  # get entity 2 vector\n",
        "  try:\n",
        "    v2 = wiki2vec.get_entity_vector(entity_2)\n",
        "  except KeyError:\n",
        "    v2 = np.random.random(300)\n",
        "\n",
        "  return cosine(v1, v2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1G1jaUNMcUd"
      },
      "source": [
        "wiki_df['SemanticDist'] = wiki_df.apply(lambda x: semantic_dist(x['SrcNameClean'], x['TgtNameClean']), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE6nl_Z2QBs0"
      },
      "source": [
        "# Create Individual Networks\n",
        "\n",
        "Next, we split the data set by individual, and use the `SourceUID`, `TargetUID`, and `SemanticDist` columns to generate network representations of participants' Wikipedia exploration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLVMt5tBc_0e"
      },
      "source": [
        "# split the data by individual\n",
        "ID_groups = wiki_df.groupby('ID')\n",
        "for ID, group in ID_groups:\n",
        "  # enforce time ordering\n",
        "  group.sort_values(by = ['TimeOrder'], inplace = True)\n",
        "  network_df = group[['TimeOrder', 'SourceUID', 'SrcNameClean', 'TargetUID', 'TgtNameClean', 'SemanticDist']].reset_index(drop = True)\n",
        "  # create an empty network\n",
        "  G = nx.Graph()\n",
        "  all_adj = []\n",
        "  edge_info = []\n",
        "  # incrementally add nodes and edges to the network\n",
        "  for index, row in network_df.iterrows():\n",
        "    from_node = row.get('SrcNameClean')\n",
        "    to_node = row.get('TgtNameClean')\n",
        "    edge_weight = row.get('SemanticDist')\n",
        "    edge_info_dict = {'from': from_node, 'to': to_node, 'weight': edge_weight}\n",
        "    edge_info.append(edge_info_dict)\n",
        "    # add edge to the network\n",
        "    G.add_edge(from_node, to_node, weight = edge_weight)\n",
        "    adj_G = nx.linalg.graphmatrix.adjacency_matrix(G, weight = 'weight')\n",
        "    all_adj.append(adj_G)\n",
        "  # save subject data to .mat file\n",
        "  filename = 'subj_' + str(ID) + '.mat'\n",
        "  mdic = {'subj': ID, 'all_adj': all_adj, 'edge_info': edge_info}\n",
        "  savemat(filename, mdic)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}